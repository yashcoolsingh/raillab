{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hotdog or Not Hotdog: Transfer learning in PyTorch \n",
    "============================\n",
    "\n",
    "Transfer learning is a useful approach in deep learning: we take an existing model, with pre-trained weights, and simply repurpose the model for another task. Often, the domains are relatively similar so a lot of the fundamentals which the network may have already learned are applicable. This is most useful when we might not have a lot of training data - the pre-trained model would likely have been trained on a very large amount of data and for a very long time. Thus, it’s feature extraction abilities in the lower layers are well optimized. All we have to do is re-train the last few layers such that, using the features the lower layers are already able to extract, we can classify the images of our choosing.\n",
    "\n",
    "In this example, we’ll use a pre-trained image classifier, and we’ll re-train the last few linear layers using a smaller dataset. The problem here is simpler (two categories, instead of the usual 1000 for ImageNet). Let’s dive in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# TODO: fill in username and password\n",
    "os.environ['http_proxy'] = \"http://username:password@proxy_server:port\" \n",
    "os.environ['https_proxy'] = \"https://username:password@proxy_server:port\" \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and editing the VGG11 model\n",
    "----------------------------------------\n",
    "\n",
    "We’ll be using VGG11 as the base for this exercise (feel free to try deeper models in your own time).\n",
    "To load the model, simply use the torchvision package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg11(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the model, the first thing is to set the `required_grad` flag false such that the weights will not be updated. Since we’re doing transfer learning, we don’t need to train the weights in the lower layers. We print the model so that you can see the output and the structure of the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    # TODO freeze all the weights\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the model details, you can see above that the final linear layer takes an input of size 4096 and outputs a vector of size 1000 - this corresponds to the 1000 categories in ImageNet. For our purposes, we want to replace this with a layer that outputs a vector of size 2: hotdog or not_hotdog. To do this, we simply change the out_features parameter of the layer `model.classifier[6]`.\n",
    "\n",
    "Next, we have to ensure that these last layers will be learned so we set its `require_grad` flag to True.\n",
    "\n",
    "Third, we initialize the weights on this new layer using the Kaiming He initialization method. We make use of the handy `model.apply()` method, supplying it with a function to initialize the weights in the Linear layers only (since Dropout and Relu layers don’t need weights initialization).\n",
    "\n",
    "In the last step, we move the entire model to the GPU for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the number of output features\n",
    "# TODO make a new layer that has only 2 outputs instead of 1000\n",
    "model.classifier[6] = ...\n",
    "\n",
    "# Set requires_grad to True on the linear layer\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Initialize the weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight.data)\n",
    "        \n",
    "model.classifier.apply(weights_init);\n",
    "\n",
    "# TODO: move the model to the GPU\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data\n",
    "------------------\n",
    "\n",
    "The data we’re using to train this model is available from [here](http://courses.ms.wits.ac.za/moodle/hotdog_nothotdog/data.zip). Download and save these into a folder named data. There are 998 images, 500 in the test set and 498 in the training set. We’ll use PyTorch’s ready made `ImageFolder` method from the `torchvision.datasets` package to load these images on the fly.\n",
    "\n",
    "First, we define the data transforms. These are used by the dataset class to transform images on-the-fly. For training, we simply take random crops of size 224x224 and apply random horizontal flipping. The images are converted to PyTorch Tensors. For the test set, we scale everything to 256 and take a center crop of the same size as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': torchvision.transforms.Compose([\n",
    "            torchvision.transforms.RandomResizedCrop(224),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor()\n",
    "        ]),\n",
    "    'test':\n",
    "            torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(256),\n",
    "            torchvision.transforms.CenterCrop(224),\n",
    "            torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "}\n",
    "\n",
    "image_dataset = {\n",
    "    x: torchvision.datasets.ImageFolder(os.path.join('./data/', x), data_transforms[x]) for x in ['train', 'test']\n",
    "}\n",
    "data_loader = {\n",
    "    x: DataLoader(image_dataset[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'test']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, we can quickly plot a few images and see what we’re dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(imgs, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    imgs = imgs.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(imgs)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(data_loader['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "imgs = torchvision.utils.make_grid(inputs)\n",
    "class_names = {0: \"hot_dog\", 1: \"not_hot_dog\"}\n",
    "imshow(imgs, title=[class_names[x.item()] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "---------------------\n",
    "\n",
    "Now the optimizer and the loss functions are defined. Note that we specify the parameters that are being optimized - in this case it’s all the layers within the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO create an SGD optimiser over the classifier's parameters. The learning rate should be 0.001, \n",
    "# the momentum should be 0.9, the weight decay 1e-6 and set Netserov monentum to true\n",
    "optimizer = ... \n",
    "\n",
    "# TODO create a corss-entropy loss criterion\n",
    "criterion = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we’re ready to begin training the model. We use the tqdm package to generate handy progress bars and train for 150 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "dataset_sizes = {x: len(image_dataset[x]) for x in ['train', 'test']}\n",
    "\n",
    "with tqdm_notebook(total=epochs,unit=\"epoch\") as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        for i, data in enumerate(data_loader['train']):\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # TODO move the data to the GPU:\n",
    "            inputs = ...\n",
    "            labels = ...\n",
    "\n",
    "            # TODO zero out the optimiser's gradient buffers\n",
    "            \n",
    "            #TODO feed the inputs through the model\n",
    "            outputs = ...\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # TODO do backpropagation and update the weights\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(predicted == labels.data)\n",
    "                \n",
    "        epoch_loss = running_loss / dataset_sizes['train']\n",
    "        epoch_acc = running_corrects / dataset_sizes['train']\n",
    "        pbar.set_postfix(loss=epoch_loss, acc=epoch_acc)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Our Model\n",
    "-------------------\n",
    "\n",
    "Now we check how our model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in data_loader['test']:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        class_names[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample some test data and feed it through our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(data_loader['test']))\n",
    "\n",
    "# Make a grid from batch\n",
    "imgs = torchvision.utils.make_grid(inputs)\n",
    "imshow(imgs, title=[class_names[x.item()] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = model(inputs.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "predicted_names = [class_names[i.item()] for i in predicted]\n",
    "print(predicted_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Using VGG-19, we could probably improve the accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
